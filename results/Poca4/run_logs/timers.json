{
    "name": "root",
    "gauges": {
        "PocaWalkerAgent.Policy.Entropy.mean": {
            "value": 2.9785399436950684,
            "min": 1.4268699884414673,
            "max": 2.9785399436950684,
            "count": 153
        },
        "PocaWalkerAgent.Policy.Entropy.sum": {
            "value": 180103.375,
            "min": 86508.2734375,
            "max": 180103.375,
            "count": 153
        },
        "PocaWalkerAgent.Step.mean": {
            "value": 9179996.0,
            "min": 59979.0,
            "max": 9179996.0,
            "count": 153
        },
        "PocaWalkerAgent.Step.sum": {
            "value": 9179996.0,
            "min": 59979.0,
            "max": 9179996.0,
            "count": 153
        },
        "PocaWalkerAgent.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": 0.3074854910373688,
            "min": 0.07202668488025665,
            "max": 0.5053062438964844,
            "count": 153
        },
        "PocaWalkerAgent.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": 333.62176513671875,
            "min": 71.45046997070312,
            "max": 527.034423828125,
            "count": 153
        },
        "PocaWalkerAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.30747053027153015,
            "min": 0.07108716666698456,
            "max": 0.5079624056816101,
            "count": 153
        },
        "PocaWalkerAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 333.60552978515625,
            "min": 70.51847076416016,
            "max": 529.8048095703125,
            "count": 153
        },
        "PocaWalkerAgent.Environment.EpisodeLength.mean": {
            "value": 273.8917748917749,
            "min": 180.14641744548285,
            "max": 928.3333333333334,
            "count": 153
        },
        "PocaWalkerAgent.Environment.EpisodeLength.sum": {
            "value": 63269.0,
            "min": 48278.0,
            "max": 70072.0,
            "count": 153
        },
        "PocaWalkerAgent.Environment.CumulativeReward.mean": {
            "value": 0.16688312132121164,
            "min": 0.11294118095846738,
            "max": 0.24864865557567492,
            "count": 153
        },
        "PocaWalkerAgent.Environment.CumulativeReward.sum": {
            "value": 38.55000102519989,
            "min": 9.300000369548798,
            "max": 62.550002098083496,
            "count": 153
        },
        "PocaWalkerAgent.Policy.ExtrinsicReward.mean": {
            "value": 1.3961039217777582,
            "min": 0.6884615590939155,
            "max": 1.6805343705279228,
            "count": 153
        },
        "PocaWalkerAgent.Policy.ExtrinsicReward.sum": {
            "value": 322.50000593066216,
            "min": 44.75000134110451,
            "max": 505.65000665187836,
            "count": 153
        },
        "PocaWalkerAgent.Environment.GroupCumulativeReward.mean": {
            "value": 0.7532467532467533,
            "min": 0.11594202898550725,
            "max": 0.8795180722891566,
            "count": 153
        },
        "PocaWalkerAgent.Environment.GroupCumulativeReward.sum": {
            "value": 174.0,
            "min": 8.0,
            "max": 279.0,
            "count": 153
        },
        "PocaWalkerAgent.Losses.PolicyLoss.mean": {
            "value": 0.04896362016184463,
            "min": 0.023754694566337595,
            "max": 0.14363896896441777,
            "count": 153
        },
        "PocaWalkerAgent.Losses.PolicyLoss.sum": {
            "value": 0.29378172097106775,
            "min": 0.12071026865548144,
            "max": 0.8618338137865067,
            "count": 153
        },
        "PocaWalkerAgent.Losses.ValueLoss.mean": {
            "value": 0.006291428455086945,
            "min": 0.001605714066277465,
            "max": 0.013831360392375952,
            "count": 153
        },
        "PocaWalkerAgent.Losses.ValueLoss.sum": {
            "value": 0.037748570730521666,
            "min": 0.00963428439766479,
            "max": 0.08298816235425571,
            "count": 153
        },
        "PocaWalkerAgent.Losses.BaselineLoss.mean": {
            "value": 0.0071764658806690316,
            "min": 0.001705598708778982,
            "max": 0.014881044051920374,
            "count": 153
        },
        "PocaWalkerAgent.Losses.BaselineLoss.sum": {
            "value": 0.04305879528401419,
            "min": 0.010233592252673892,
            "max": 0.08928626431152224,
            "count": 153
        },
        "PocaWalkerAgent.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 153
        },
        "PocaWalkerAgent.Policy.LearningRate.sum": {
            "value": 0.0017999999999999997,
            "min": 0.0014999999999999998,
            "max": 0.0017999999999999997,
            "count": 153
        },
        "PocaWalkerAgent.Policy.Epsilon.mean": {
            "value": 0.2000000000000001,
            "min": 0.2000000000000001,
            "max": 0.2000000000000001,
            "count": 153
        },
        "PocaWalkerAgent.Policy.Epsilon.sum": {
            "value": 1.2000000000000006,
            "min": 1.0000000000000004,
            "max": 1.2000000000000006,
            "count": 153
        },
        "PocaWalkerAgent.Policy.Beta.mean": {
            "value": 0.010000000000000002,
            "min": 0.010000000000000002,
            "max": 0.010000000000000002,
            "count": 153
        },
        "PocaWalkerAgent.Policy.Beta.sum": {
            "value": 0.06000000000000001,
            "min": 0.05000000000000001,
            "max": 0.06000000000000001,
            "count": 153
        },
        "PocaWalkerAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 153
        },
        "PocaWalkerAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 153
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1669162431",
        "python_version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\giova\\Desktop\\Magistrale\\DeepLearningForGamesAndSimulations\\Project\\Code\\DLGSproject\\Scripts\\mlagents-learn config/OurConfig/multiagent_poca.yaml --run-id=Poca4",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1669187020"
    },
    "total": 24588.9856692,
    "count": 1,
    "self": 0.025705500003823545,
    "children": {
        "run_training.setup": {
            "total": 0.17234490000000002,
            "count": 1,
            "self": 0.17234490000000002
        },
        "TrainerController.start_learning": {
            "total": 24588.787618799997,
            "count": 1,
            "self": 14.241929299496405,
            "children": {
                "TrainerController._reset_env": {
                    "total": 14.6919712,
                    "count": 1,
                    "self": 14.6919712
                },
                "TrainerController.advance": {
                    "total": 24559.6893491005,
                    "count": 408018,
                    "self": 15.456474600130605,
                    "children": {
                        "env_step": {
                            "total": 10673.987021700326,
                            "count": 408018,
                            "self": 9532.945476299406,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1132.5758753005812,
                                    "count": 408018,
                                    "self": 45.36140410069129,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1087.2144711998899,
                                            "count": 401711,
                                            "self": 391.0734308001138,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 696.1410403997761,
                                                    "count": 401711,
                                                    "self": 696.1410403997761
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 8.465670100339395,
                                    "count": 408017,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 24565.51517960024,
                                            "count": 408017,
                                            "is_parallel": true,
                                            "self": 16114.950644999162,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.007021500000000458,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00014159999999918682,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.006879900000001271,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.006879900000001271
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 8450.557513101077,
                                                    "count": 408017,
                                                    "is_parallel": true,
                                                    "self": 90.07174000140549,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 99.47184110038725,
                                                            "count": 408017,
                                                            "is_parallel": true,
                                                            "self": 99.47184110038725
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 8032.79713619981,
                                                            "count": 408017,
                                                            "is_parallel": true,
                                                            "self": 8032.79713619981
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 228.21679579947534,
                                                            "count": 408017,
                                                            "is_parallel": true,
                                                            "self": 48.06886549990048,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 180.14793029957485,
                                                                    "count": 1632068,
                                                                    "is_parallel": true,
                                                                    "self": 180.14793029957485
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 13870.24585280004,
                            "count": 408017,
                            "self": 22.48098070056767,
                            "children": {
                                "process_trajectory": {
                                    "total": 5259.194296899471,
                                    "count": 408017,
                                    "self": 5256.987289699472,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 2.207007199998543,
                                            "count": 18,
                                            "self": 2.207007199998543
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 8588.570575200001,
                                    "count": 890,
                                    "self": 2076.1931232999586,
                                    "children": {
                                        "TorchPOCAOptimizer.update": {
                                            "total": 6512.377451900043,
                                            "count": 26700,
                                            "self": 6512.377451900043
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.6000012692529708e-06,
                    "count": 1,
                    "self": 1.6000012692529708e-06
                },
                "TrainerController._save_models": {
                    "total": 0.16436759999851347,
                    "count": 1,
                    "self": 0.02445879999504541,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.13990880000346806,
                            "count": 1,
                            "self": 0.13990880000346806
                        }
                    }
                }
            }
        }
    }
}