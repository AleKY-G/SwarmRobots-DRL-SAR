{
    "name": "root",
    "gauges": {
        "WalkerAgentMulti.Policy.Entropy.mean": {
            "value": 0.32196834683418274,
            "min": 0.3116682767868042,
            "max": 1.8995498418807983,
            "count": 125
        },
        "WalkerAgentMulti.Policy.Entropy.sum": {
            "value": 12865.85546875,
            "min": 12439.3037109375,
            "max": 77683.9921875,
            "count": 125
        },
        "WalkerAgentMulti.Step.mean": {
            "value": 4999964.0,
            "min": 39936.0,
            "max": 4999964.0,
            "count": 125
        },
        "WalkerAgentMulti.Step.sum": {
            "value": 4999964.0,
            "min": 39936.0,
            "max": 4999964.0,
            "count": 125
        },
        "WalkerAgentMulti.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.8253861665725708,
            "min": -0.7736527919769287,
            "max": 2.4857592582702637,
            "count": 125
        },
        "WalkerAgentMulti.Policy.ExtrinsicValueEstimate.sum": {
            "value": 1414.67431640625,
            "min": -497.458740234375,
            "max": 1998.550537109375,
            "count": 125
        },
        "WalkerAgentMulti.Losses.PolicyLoss.mean": {
            "value": 0.2473817187827189,
            "min": 0.2434958837170816,
            "max": 0.2545816513756207,
            "count": 125
        },
        "WalkerAgentMulti.Losses.PolicyLoss.sum": {
            "value": 39.82845672401774,
            "min": 28.643016101772236,
            "max": 41.96570628659625,
            "count": 125
        },
        "WalkerAgentMulti.Losses.ValueLoss.mean": {
            "value": 1.6502151196335484,
            "min": 0.08042724917272945,
            "max": 1.6502151196335484,
            "count": 125
        },
        "WalkerAgentMulti.Losses.ValueLoss.sum": {
            "value": 265.6846342610013,
            "min": 9.694705368747357,
            "max": 265.6846342610013,
            "count": 125
        },
        "WalkerAgentMulti.Policy.LearningRate.mean": {
            "value": 1.1924061864154032e-06,
            "min": 1.1924061864154032e-06,
            "max": 0.0002986342215078912,
            "count": 125
        },
        "WalkerAgentMulti.Policy.LearningRate.sum": {
            "value": 0.00019197739601287993,
            "min": 0.00019197739601287993,
            "max": 0.044325423784858875,
            "count": 125
        },
        "WalkerAgentMulti.Policy.Epsilon.mean": {
            "value": 0.09999999999999996,
            "min": 0.09999999999999995,
            "max": 0.09999999999999999,
            "count": 125
        },
        "WalkerAgentMulti.Policy.Epsilon.sum": {
            "value": 16.099999999999994,
            "min": 11.399999999999999,
            "max": 16.899999999999995,
            "count": 125
        },
        "WalkerAgentMulti.Policy.Beta.mean": {
            "value": 0.0005000000000000001,
            "min": 0.0005,
            "max": 0.0005000000000000002,
            "count": 125
        },
        "WalkerAgentMulti.Policy.Beta.sum": {
            "value": 0.08050000000000002,
            "min": 0.05700000000000002,
            "max": 0.08450000000000002,
            "count": 125
        },
        "WalkerAgentMulti.Environment.EpisodeLength.mean": {
            "value": 141.9102564102564,
            "min": 108.34883720930233,
            "max": 866.0,
            "count": 125
        },
        "WalkerAgentMulti.Environment.EpisodeLength.sum": {
            "value": 44276.0,
            "min": 28696.0,
            "max": 47796.0,
            "count": 125
        },
        "WalkerAgentMulti.Environment.CumulativeReward.mean": {
            "value": 4.514975697709271,
            "min": -6.912414436228573,
            "max": 4.879372013083031,
            "count": 125
        },
        "WalkerAgentMulti.Environment.CumulativeReward.sum": {
            "value": 1390.6125148944557,
            "min": -390.59597574174404,
            "max": 1678.5039725005627,
            "count": 125
        },
        "WalkerAgentMulti.Policy.ExtrinsicReward.mean": {
            "value": 4.514975697709271,
            "min": -6.912414436228573,
            "max": 4.879372013083031,
            "count": 125
        },
        "WalkerAgentMulti.Policy.ExtrinsicReward.sum": {
            "value": 1390.6125148944557,
            "min": -390.59597574174404,
            "max": 1678.5039725005627,
            "count": 125
        },
        "WalkerAgentMulti.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 125
        },
        "WalkerAgentMulti.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 125
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1670720122",
        "python_version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\giova\\Desktop\\Magistrale\\DeepLearningForGamesAndSimulations\\Project\\Code\\DLGSproject\\Scripts\\mlagents-learn config\\OurConfig\\multiagent256.yaml --env=BuiltEnvs\\4AgentNoCommHigherTargetTRAIN --no-graphics --run-id=4agentsNoCommHigherTarget2",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1670734327"
    },
    "total": 14204.544784099999,
    "count": 1,
    "self": 0.9708423999982188,
    "children": {
        "run_training.setup": {
            "total": 0.09001669999999995,
            "count": 1,
            "self": 0.09001669999999995
        },
        "TrainerController.start_learning": {
            "total": 14203.483925,
            "count": 1,
            "self": 5.979474299931098,
            "children": {
                "TrainerController._reset_env": {
                    "total": 1.7590036999999998,
                    "count": 1,
                    "self": 1.7590036999999998
                },
                "TrainerController.advance": {
                    "total": 14195.663591100069,
                    "count": 213934,
                    "self": 5.830371300240586,
                    "children": {
                        "env_step": {
                            "total": 4120.455979899752,
                            "count": 213934,
                            "self": 3788.1709579996973,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 328.5653050002876,
                                    "count": 213934,
                                    "self": 16.910736900496204,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 311.6545680997914,
                                            "count": 208365,
                                            "self": 63.41178159985634,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 248.24278649993505,
                                                    "count": 208365,
                                                    "self": 248.24278649993505
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 3.7197168997668153,
                                    "count": 213934,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 14196.066015700333,
                                            "count": 213934,
                                            "is_parallel": true,
                                            "self": 10850.836565600259,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0006363000000000341,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00022440000000023552,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00041189999999979854,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00041189999999979854
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 3345.228813800074,
                                                    "count": 213934,
                                                    "is_parallel": true,
                                                    "self": 51.41485030045624,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 68.48741289962304,
                                                            "count": 213934,
                                                            "is_parallel": true,
                                                            "self": 68.48741289962304
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 3083.4090581001406,
                                                            "count": 213934,
                                                            "is_parallel": true,
                                                            "self": 3083.4090581001406
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 141.9174924998544,
                                                            "count": 213934,
                                                            "is_parallel": true,
                                                            "self": 44.78489790043028,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 97.13259459942412,
                                                                    "count": 427868,
                                                                    "is_parallel": true,
                                                                    "self": 97.13259459942412
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 10069.377239900075,
                            "count": 213934,
                            "self": 10.340159400529956,
                            "children": {
                                "process_trajectory": {
                                    "total": 436.57877409957393,
                                    "count": 213934,
                                    "self": 435.9977955995731,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.5809785000008105,
                                            "count": 10,
                                            "self": 0.5809785000008105
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 9622.45830639997,
                                    "count": 19675,
                                    "self": 1106.090748499193,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 8516.367557900778,
                                            "count": 1468746,
                                            "self": 8516.367557900778
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.000009307172149e-07,
                    "count": 1,
                    "self": 6.000009307172149e-07
                },
                "TrainerController._save_models": {
                    "total": 0.08185529999900609,
                    "count": 1,
                    "self": 0.026625199998306925,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.05523010000069917,
                            "count": 1,
                            "self": 0.05523010000069917
                        }
                    }
                }
            }
        }
    }
}